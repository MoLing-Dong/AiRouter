import time
import json
from typing import Dict, List, Any, Optional
from .base import BaseAdapter, ChatRequest, ChatResponse, Message, HealthStatus
import openai
from app.utils.logging_config import get_factory_logger

# Get logger
logger = get_factory_logger()


class ZhipuAdapter(BaseAdapter):
    """Zhipu model adapter - using OpenAI library"""

    def __init__(self, model_config: Dict[str, Any], api_key: str):
        super().__init__(model_config, api_key)
        # Ensure base_url does not end with /, avoid OpenAI library automatically adding path
        base_url = self.base_url.rstrip("/")
        # Initialize OpenAI client with optimized settings
        self.client = openai.AsyncOpenAI(
            api_key=api_key,
            base_url=base_url,
            timeout=10.0,  # å‡å°‘è¶…æ—¶æ—¶é—´
            max_retries=1,  # å‡å°‘é‡è¯•æ¬¡æ•°ä»¥é¿å…å»¶è¿Ÿ
        )

    def format_messages(self, messages: List[Message]) -> List[Dict]:
        """Format messages to OpenAI format"""
        formatted_messages = []
        for msg in messages:
            formatted_msg = {"role": msg.role.value, "content": msg.content}
            if msg.name:
                formatted_msg["name"] = msg.name
            formatted_messages.append(formatted_msg)
        return formatted_messages

    def _convert_to_openai_format(self, zhipu_chunk: Dict[str, Any]) -> Dict[str, Any]:
        """Convert Zhipu chunk format to OpenAI standard format"""
        openai_chunk = {
            "id": zhipu_chunk.get("id"),
            "object": "chat.completion.chunk",
            "created": zhipu_chunk.get("created"),
            "model": zhipu_chunk.get("model"),
            "choices": [],
        }

        if zhipu_chunk.get("choices"):
            for choice in zhipu_chunk["choices"]:
                delta = choice.get("delta", {})
                openai_delta = {}

                # å¤„ç†å¸¸è§„å†…å®¹
                if delta.get("content"):
                    openai_delta["content"] = delta["content"]

                # å¤„ç†æ™ºè°±ç‰¹æœ‰çš„æŽ¨ç†å†…å®¹ - ä¿æŒä¸ºæ€è€ƒå†…å®¹
                elif delta.get("reasoning_content"):
                    # ä¿æŒæŽ¨ç†å†…å®¹ä½œä¸ºç‹¬ç«‹çš„æ€è€ƒå­—æ®µ
                    openai_delta["reasoning_content"] = delta["reasoning_content"]
                    # æˆ–è€…ä½¿ç”¨æ›´é€šç”¨çš„æ€è€ƒå­—æ®µå
                    openai_delta["thinking"] = delta["reasoning_content"]

                # å¤„ç†è§’è‰²
                if delta.get("role"):
                    openai_delta["role"] = delta["role"]

                # å¤„ç†å·¥å…·è°ƒç”¨
                if delta.get("tool_calls"):
                    openai_delta["tool_calls"] = delta["tool_calls"]
                if delta.get("function_call"):
                    openai_delta["function_call"] = delta["function_call"]

                openai_choice = {
                    "index": choice.get("index", 0),
                    "delta": openai_delta,
                    "finish_reason": choice.get("finish_reason"),
                    "logprobs": choice.get("logprobs"),
                }

                openai_chunk["choices"].append(openai_choice)

        return openai_chunk

    async def chat_completion(self, request: ChatRequest) -> ChatResponse:
        """Execute Zhipu chat completion request - using OpenAI library"""
        start_time = time.time()

        try:
            # Build request parameters
            params = {
                "model": self.model_name,
                "messages": self.format_messages(request.messages),
                "max_tokens": request.max_tokens
                or self.model_config.get("max_tokens", 4096),
                "temperature": request.temperature,
                "top_p": request.top_p,
                "frequency_penalty": request.frequency_penalty,
                "presence_penalty": request.presence_penalty,
                "stream": request.stream,
            }

            # Filter None values
            filtered_params = {k: v for k, v in params.items() if v is not None}

            # Use OpenAI library to send request
            response = await self.client.chat.completions.create(**filtered_params)

            # Calculate response time
            response_time = time.time() - start_time

            # Update metrics
            tokens_used = response.usage.total_tokens if response.usage else 0
            self.update_metrics(response_time, True, tokens_used)

            # Build standard response - convert OpenAI object to dictionary
            chat_response = ChatResponse(
                id=response.id,
                created=response.created,
                model=response.model,
                choices=[choice.model_dump() for choice in response.choices],
                usage=response.usage.model_dump() if response.usage else None,
                system_fingerprint=getattr(response, "system_fingerprint", None),
            )

            return chat_response

        except openai.APIError as e:
            response_time = time.time() - start_time
            self.update_metrics(response_time, False)

            # Update health status based on error status code
            if hasattr(e, "status_code"):
                if e.status_code >= 500:
                    self.health_status = HealthStatus.UNHEALTHY
                elif e.status_code >= 400:
                    self.health_status = HealthStatus.DEGRADED

            raise Exception(f"Zhipu API error: {str(e)}")

        except Exception as e:
            response_time = time.time() - start_time
            self.update_metrics(response_time, False)
            self.health_status = HealthStatus.UNHEALTHY
            raise Exception(f"Zhipu adapter error: {str(e)}")

    async def stream_chat_completion(self, request: ChatRequest):
        """Execute Zhipu stream chat completion request - using OpenAI library"""
        import asyncio

        start_time = time.time()
        logger.info(f"ðŸ”¥ Zhipué€‚é…å™¨å¼€å§‹æµå¼è¯·æ±‚ - æ¨¡åž‹: {self.model_name}")

        try:
            # è®¡æ—¶ï¼šå‚æ•°æž„å»º
            param_start = time.time()

            # Build request parameters
            params = {
                "model": self.model_name,
                "messages": self.format_messages(request.messages),
                "max_tokens": request.max_tokens
                or self.model_config.get("max_tokens", 4096),
                "temperature": request.temperature,
                "top_p": request.top_p,
                "frequency_penalty": request.frequency_penalty,
                "presence_penalty": request.presence_penalty,
                "stream": True,  # Force enable streaming
            }

            # Filter None values
            filtered_params = {k: v for k, v in params.items() if v is not None}

            param_time = time.time() - param_start
            logger.info(f"ðŸ“¤ å‚æ•°æž„å»ºå®Œæˆ ({param_time*1000:.1f}ms) - å‘é€åˆ°Zhipu")

            # è®¡æ—¶ï¼šAPIè°ƒç”¨
            api_start = time.time()
            stream = await self.client.chat.completions.create(**filtered_params)
            api_time = time.time() - api_start
            logger.info(f"ðŸš€ APIè¿žæŽ¥å»ºç«‹å®Œæˆ ({api_time*1000:.1f}ms)")

            # å®žæ—¶chunkè½¬å‘æœºåˆ¶
            first_chunk_received = False
            chunk_count = 0

            # ä½¿ç”¨å¼‚æ­¥è¿­ä»£å™¨å®žçŽ°æŽ¥æ”¶åˆ°å°±ç«‹å³è½¬å‘
            async for chunk in stream:
                chunk_count += 1

                # é¦–ä¸ªchunkæ€§èƒ½ç›‘æŽ§
                if not first_chunk_received:
                    first_chunk_received = True
                    delay = time.time() - start_time
                    logger.info(f"âš¡ é¦–ä¸ªchunkæŽ¥æ”¶ï¼Œå»¶è¿Ÿ: {delay:.3f}s")

                # è¿‡æ»¤ç©ºchunk - æ£€æŸ¥æ˜¯å¦æœ‰å®žé™…å†…å®¹
                chunk_dict = chunk.model_dump()
                has_content = False

                if chunk_dict.get("choices"):
                    for choice in chunk_dict["choices"]:
                        delta = choice.get("delta", {})

                        # æ£€æŸ¥å¸¸è§„å†…å®¹
                        if delta.get("content") and delta["content"].strip():
                            has_content = True
                            break

                        # æ£€æŸ¥æŽ¨ç†å†…å®¹ (Zhipuç‰¹æœ‰)
                        if (
                            delta.get("reasoning_content")
                            and delta["reasoning_content"].strip()
                        ):
                            has_content = True
                            break

                        # æ£€æŸ¥è§’è‰²å˜åŒ–æˆ–ç»“æŸæ ‡å¿—
                        if delta.get("role") or choice.get("finish_reason"):
                            has_content = True
                            break

                        # æ£€æŸ¥å·¥å…·è°ƒç”¨
                        if delta.get("tool_calls") or delta.get("function_call"):
                            has_content = True
                            break

                # åªè½¬å‘æœ‰å†…å®¹çš„chunk
                if has_content:
                    # è½¬æ¢ä¸ºOpenAIæ ‡å‡†æ ¼å¼
                    openai_chunk = self._convert_to_openai_format(chunk_dict)
                    # é›¶å»¶è¿Ÿè½¬æ¢å’Œè½¬å‘ - ä¿æŒSSEæ ¼å¼
                    sse_chunk = (
                        f"data: {json.dumps(openai_chunk, ensure_ascii=False)}\n\n"
                    )
                    yield sse_chunk
                else:
                    # è®°å½•ç©ºchunkä½†ä¸è½¬å‘ - æ˜¾ç¤ºè¯¦ç»†ä¿¡æ¯ç”¨äºŽè°ƒè¯•
                    logger.debug(f"ðŸ”‡ è·³è¿‡ç©ºchunk #{chunk_count}: {chunk_dict}")

            total_time = time.time() - start_time
            logger.info(
                f"âœ… Zhipuå®žæ—¶æµå¼å“åº”å®Œæˆ - æ€»è€—æ—¶: {total_time:.3f}ç§’ï¼Œå¤„ç†chunk: {chunk_count}"
            )

            # Update metrics
            response_time = time.time() - start_time
            self.update_metrics(response_time, True)

        except openai.APIError as e:
            response_time = time.time() - start_time
            self.update_metrics(response_time, False)

            # Update health status based on error status code
            if hasattr(e, "status_code"):
                if e.status_code >= 500:
                    self.health_status = HealthStatus.UNHEALTHY
                elif e.status_code >= 400:
                    self.health_status = HealthStatus.DEGRADED

            raise Exception(f"Zhipu stream API error: {str(e)}")

        except Exception as e:
            response_time = time.time() - start_time
            self.update_metrics(response_time, False)
            self.health_status = HealthStatus.UNHEALTHY
            raise Exception(f"Zhipu stream adapter error: {str(e)}")

    async def health_check(self) -> HealthStatus:
        """Execute Zhipu health check - using OpenAI library"""
        try:

            # Try simple chat request
            try:
                # Send a simple test request
                test_response = await self.client.chat.completions.create(
                    model=self.model_name,
                    messages=[{"role": "user", "content": "test"}],
                    max_tokens=1,
                )
                logger.info(
                    f"ZhipuAdapter health check successful - test chat completion"
                )
                self.health_status = HealthStatus.HEALTHY
                self.metrics.last_health_check = time.time()
                return HealthStatus.HEALTHY
            except Exception as e:
                logger.info(f"Test chat request failed: {str(e)}")

            # If all fail, mark as degraded
            logger.info(f"ZhipuAdapter health check failed, mark as degraded")
            self.health_status = HealthStatus.DEGRADED
            return HealthStatus.DEGRADED

        except openai.AuthenticationError:
            # Authentication error
            self.health_status = HealthStatus.UNHEALTHY
            return HealthStatus.UNHEALTHY
        except openai.APIError as e:
            # API error
            if hasattr(e, "status_code") and e.status_code == 401:
                self.health_status = HealthStatus.UNHEALTHY
            else:
                self.health_status = HealthStatus.DEGRADED
            return self.health_status
        except Exception as e:
            # Other error
            self.health_status = HealthStatus.UNHEALTHY
            return HealthStatus.UNHEALTHY

    async def create_embedding(self, text: str) -> Dict[str, Any]:
        """Create text embedding - using OpenAI library"""
        try:
            response = await self.client.embeddings.create(
                model="text-embedding-v1", input=text
            )

            return {
                "data": response.data,
                "model": response.model,
                "usage": response.usage,
            }

        except Exception as e:
            raise Exception(f"Zhipu embedding creation error: {str(e)}")

    async def list_models(self) -> List[Dict[str, Any]]:
        """Get available model list"""
        try:
            response = await self.client.get(f"{self.base_url}/v1/models")
            response.raise_for_status()
            return response.json().get("data", [])

        except Exception as e:
            raise Exception(f"Zhipu model list get error: {str(e)}")

    async def create_image(
        self,
        prompt: str,
        n: int = 1,
        size: str = "1024x1024",
        quality: str = "standard",
        style: str = "vivid",
        response_format: str = "url",
    ) -> List[Dict[str, Any]]:
        """Create image from text prompt (Zhipu does not support image generation)"""
        raise NotImplementedError("Zhipu does not support image generation")

    async def edit_image(
        self,
        image: str,
        prompt: str,
        mask: Optional[str] = None,
        n: int = 1,
        size: str = "1024x1024",
        response_format: str = "url",
    ) -> List[Dict[str, Any]]:
        """Edit image based on prompt and optional mask (Zhipu does not support image editing)"""
        raise NotImplementedError("Zhipu does not support image editing")

    async def create_image_variation(
        self,
        image: str,
        n: int = 1,
        size: str = "1024x1024",
        response_format: str = "url",
    ) -> List[Dict[str, Any]]:
        """Create image variations from base image (Zhipu does not support image variations)"""
        raise NotImplementedError("Zhipu does not support image variations")
