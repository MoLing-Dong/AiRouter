"""
å¢å¼ºæ¨¡å‹æœåŠ¡ - é›†æˆå¼‚æ­¥æ•°æ®åº“ã€Redisç¼“å­˜å’Œæ€§èƒ½ä¼˜åŒ–
æä¾›é«˜æ€§èƒ½çš„æ¨¡å‹ç®¡ç†å’ŒæŸ¥è¯¢æœåŠ¡
"""

import asyncio
import json
from typing import Dict, List, Optional, Any, Tuple
from datetime import datetime, timedelta
from contextlib import asynccontextmanager
import redis.asyncio as redis
from sqlalchemy import text

from ..database.async_database_service import async_db_service
# from app.models.sqlmodel_models import (
#     LLMModel, LLMProvider, LLMModelProvider, QueryBuilder,
#     HealthStatus, ModelResponse, PerformanceMetrics
# )
from config.settings import settings
from app.utils.logging_config import get_factory_logger

logger = get_factory_logger()


class EnhancedModelService:
    """å¢å¼ºæ¨¡å‹æœåŠ¡ - é›†æˆç¼“å­˜ã€å¼‚æ­¥æ•°æ®åº“å’Œæ€§èƒ½ä¼˜åŒ–"""

    def __init__(self):
        # Redisè¿æ¥é…ç½®
        self.redis_client: Optional[redis.Redis] = None
        self.cache_enabled = True
        self.cache_ttl = {
            "models": 300,  # 5åˆ†é’Ÿ
            "providers": 600,  # 10åˆ†é’Ÿ
            "performance": 180,  # 3åˆ†é’Ÿ
            "health": 60,  # 1åˆ†é’Ÿ
        }
        
        # æ€§èƒ½ç›‘æ§
        self.performance_metrics = {
            "cache_hits": 0,
            "cache_misses": 0,
            "db_queries": 0,
            "avg_query_time": 0.0,
        }
        
        # æ‰¹å¤„ç†é…ç½®
        self.batch_size = 50
        self.batch_timeout = 5.0  # 5ç§’

    async def initialize(self):
        """åˆå§‹åŒ–æœåŠ¡"""
        try:
            # åˆå§‹åŒ–Redisè¿æ¥
            self.redis_client = redis.from_url(
                settings.REDIS_URL,
                encoding="utf-8",
                decode_responses=True,
                socket_connect_timeout=5,
                socket_keepalive=True,
                health_check_interval=30
            )
            
            # æµ‹è¯•Redisè¿æ¥
            await self.redis_client.ping()
            logger.info("âœ… Redis connection established")
            
        except Exception as e:
            logger.warning(f"âš ï¸ Redis connection failed: {e}. Cache disabled.")
            self.cache_enabled = False

    async def close(self):
        """å…³é—­æœåŠ¡"""
        if self.redis_client:
            await self.redis_client.close()
        await async_db_service.close()

    # ==================== ç¼“å­˜ç®¡ç† ====================

    def _get_cache_key(self, prefix: str, *args, **kwargs) -> str:
        """ç”Ÿæˆç¼“å­˜é”®"""
        key_parts = [prefix] + [str(arg) for arg in args]
        if kwargs:
            key_parts.append(json.dumps(kwargs, sort_keys=True))
        return ":".join(key_parts)

    async def _get_from_cache(self, cache_key: str) -> Optional[Any]:
        """ä»ç¼“å­˜è·å–æ•°æ®"""
        if not self.cache_enabled or not self.redis_client:
            return None
            
        try:
            data = await self.redis_client.get(cache_key)
            if data:
                self.performance_metrics["cache_hits"] += 1
                return json.loads(data)
            else:
                self.performance_metrics["cache_misses"] += 1
                return None
        except Exception as e:
            logger.debug(f"Cache get error: {e}")
            return None

    async def _set_cache(self, cache_key: str, data: Any, ttl: int):
        """è®¾ç½®ç¼“å­˜æ•°æ®"""
        if not self.cache_enabled or not self.redis_client:
            return
            
        try:
            await self.redis_client.setex(
                cache_key, 
                ttl, 
                json.dumps(data, default=str)
            )
        except Exception as e:
            logger.debug(f"Cache set error: {e}")

    async def _invalidate_cache_pattern(self, pattern: str):
        """æŒ‰æ¨¡å¼åˆ é™¤ç¼“å­˜"""
        if not self.cache_enabled or not self.redis_client:
            return
            
        try:
            keys = await self.redis_client.keys(pattern)
            if keys:
                await self.redis_client.delete(*keys)
                logger.debug(f"Invalidated {len(keys)} cache keys with pattern: {pattern}")
        except Exception as e:
            logger.debug(f"Cache invalidation error: {e}")

    # ==================== æ¨¡å‹æŸ¥è¯¢æœåŠ¡ ====================

    async def get_all_models_enhanced(
        self, 
        is_enabled: Optional[bool] = None,
        include_relationships: bool = True,
        use_cache: bool = True
    ) -> List[Dict[str, Any]]:
        """
        è·å–æ‰€æœ‰æ¨¡å‹ï¼ˆå¢å¼ºç‰ˆï¼‰ - æ”¯æŒç¼“å­˜å’Œæ€§èƒ½ä¼˜åŒ–
        """
        cache_key = self._get_cache_key(
            "models:all", is_enabled, include_relationships
        )
        
        # å°è¯•ä»ç¼“å­˜è·å–
        if use_cache:
            cached_data = await self._get_from_cache(cache_key)
            if cached_data:
                return cached_data

        # ä»æ•°æ®åº“æŸ¥è¯¢
        start_time = datetime.now()
        
        if include_relationships:
            models_data = await async_db_service.get_all_models_with_relationships(is_enabled)
        else:
            # ç®€åŒ–æŸ¥è¯¢ï¼Œåªè·å–åŸºæœ¬ä¿¡æ¯
            async with async_db_service.get_session() as session:
                from sqlalchemy import select
                query = select(LLMModel)
                if is_enabled is not None:
                    query = query.where(LLMModel.is_enabled == is_enabled)
                
                result = await session.execute(query)
                models = result.scalars().all()
                
                models_data = [
                    {
                        "id": model.id,
                        "name": model.name,
                        "llm_type": model.llm_type,
                        "description": model.description,
                        "is_enabled": model.is_enabled,
                        "created_at": model.created_at,
                        "updated_at": model.updated_at,
                    }
                    for model in models
                ]

        query_time = (datetime.now() - start_time).total_seconds()
        self.performance_metrics["db_queries"] += 1
        
        # æ›´æ–°å¹³å‡æŸ¥è¯¢æ—¶é—´
        total_queries = self.performance_metrics["db_queries"]
        current_avg = self.performance_metrics["avg_query_time"]
        self.performance_metrics["avg_query_time"] = (
            current_avg * (total_queries - 1) + query_time
        ) / total_queries

        # ç¼“å­˜ç»“æœ
        if use_cache:
            await self._set_cache(cache_key, models_data, self.cache_ttl["models"])

        logger.info(
            f"âœ… Retrieved {len(models_data)} models in {query_time:.3f}s "
            f"(cached: {use_cache and cached_data is not None})"
        )
        
        return models_data

    async def get_model_by_name_enhanced(
        self, 
        model_name: str, 
        include_relationships: bool = True,
        use_cache: bool = True
    ) -> Optional[Dict[str, Any]]:
        """
        è·å–å•ä¸ªæ¨¡å‹ï¼ˆå¢å¼ºç‰ˆï¼‰
        """
        cache_key = self._get_cache_key("models:single", model_name, include_relationships)
        
        # å°è¯•ä»ç¼“å­˜è·å–
        if use_cache:
            cached_data = await self._get_from_cache(cache_key)
            if cached_data:
                return cached_data

        # ä»æ•°æ®åº“æŸ¥è¯¢
        model_data = await async_db_service.get_model_by_name_optimized(
            model_name, include_relationships
        )

        # ç¼“å­˜ç»“æœ
        if use_cache and model_data:
            await self._set_cache(cache_key, model_data, self.cache_ttl["models"])

        return model_data

    async def get_healthy_models(self, use_cache: bool = True) -> List[Dict[str, Any]]:
        """
        è·å–å¥åº·çš„æ¨¡å‹ï¼ˆè‡³å°‘æœ‰ä¸€ä¸ªå¥åº·çš„æä¾›å•†ï¼‰
        """
        cache_key = self._get_cache_key("models:healthy")
        
        # å°è¯•ä»ç¼“å­˜è·å–
        if use_cache:
            cached_data = await self._get_from_cache(cache_key)
            if cached_data:
                return cached_data

        # ä½¿ç”¨ä¼˜åŒ–æŸ¥è¯¢
        async with async_db_service.get_session() as session:
            query = QueryBuilder.get_models_with_healthy_providers()
            result = await session.execute(query)
            models = result.scalars().all()
            
            models_data = [
                {
                    "id": model.id,
                    "name": model.name,
                    "llm_type": model.llm_type,
                    "description": model.description,
                    "is_enabled": model.is_enabled,
                }
                for model in models
            ]

        # ç¼“å­˜ç»“æœï¼ˆè¾ƒçŸ­TTLï¼Œå› ä¸ºå¥åº·çŠ¶æ€å˜åŒ–è¾ƒå¿«ï¼‰
        if use_cache:
            await self._set_cache(cache_key, models_data, self.cache_ttl["health"])

        return models_data

    # ==================== æ€§èƒ½åˆ†ææœåŠ¡ ====================

    async def get_model_performance_analysis(
        self, 
        model_name: str, 
        days: int = 7,
        use_cache: bool = True
    ) -> Optional[Dict[str, Any]]:
        """
        è·å–æ¨¡å‹æ€§èƒ½åˆ†æ
        """
        cache_key = self._get_cache_key("performance:model", model_name, days)
        
        # å°è¯•ä»ç¼“å­˜è·å–
        if use_cache:
            cached_data = await self._get_from_cache(cache_key)
            if cached_data:
                return cached_data

        # è·å–æ¨¡å‹ä¿¡æ¯
        model_data = await self.get_model_by_name_enhanced(model_name, True, use_cache)
        if not model_data:
            return None

        # è®¡ç®—æ€§èƒ½æŒ‡æ ‡
        total_requests = 0
        total_successful = 0
        total_cost = 0.0
        response_times = []
        provider_count = 0

        for provider in model_data.get("providers", []):
            if provider.get("is_enabled"):
                provider_count += 1
                total_requests += provider.get("total_requests", 0)
                total_successful += provider.get("successful_requests", 0) 
                total_cost += provider.get("total_cost", 0.0)
                
                if provider.get("response_time_avg", 0) > 0:
                    response_times.append(provider["response_time_avg"])

        # è®¡ç®—ç»¼åˆæŒ‡æ ‡
        avg_response_time = sum(response_times) / len(response_times) if response_times else 0.0
        success_rate = total_successful / total_requests if total_requests > 0 else 0.0
        avg_score = sum(p.get("overall_score", 0) for p in model_data.get("providers", [])) / provider_count if provider_count > 0 else 0.0

        performance_data = {
            "model_name": model_name,
            "model_id": model_data["id"],
            "analysis_period_days": days,
            "provider_count": provider_count,
            "total_requests": total_requests,
            "successful_requests": total_successful,
            "failed_requests": total_requests - total_successful,
            "success_rate": round(success_rate, 3),
            "avg_response_time": round(avg_response_time, 3),
            "total_cost": round(total_cost, 4),
            "cost_per_request": round(total_cost / total_requests, 6) if total_requests > 0 else 0.0,
            "overall_score": round(avg_score, 3),
            "providers": model_data.get("providers", []),
            "generated_at": datetime.utcnow().isoformat(),
        }

        # ç¼“å­˜ç»“æœ
        if use_cache:
            await self._set_cache(cache_key, performance_data, self.cache_ttl["performance"])

        return performance_data

    async def get_provider_performance_summary(
        self, 
        days: int = 7,
        use_cache: bool = True
    ) -> List[Dict[str, Any]]:
        """
        è·å–æä¾›å•†æ€§èƒ½æ±‡æ€»
        """
        cache_key = self._get_cache_key("performance:providers", days)
        
        # å°è¯•ä»ç¼“å­˜è·å–
        if use_cache:
            cached_data = await self._get_from_cache(cache_key)
            if cached_data:
                return cached_data

        # ä»å¼‚æ­¥æ•°æ®åº“æœåŠ¡è·å–èšåˆæ•°æ®
        providers_data = await async_db_service.get_provider_performance_aggregated(days)

        # ç¼“å­˜ç»“æœ
        if use_cache:
            await self._set_cache(cache_key, providers_data, self.cache_ttl["performance"])

        return providers_data

    # ==================== æ‰¹é‡æ“ä½œæœåŠ¡ ====================

    async def batch_update_model_metrics(
        self, 
        updates: List[Dict[str, Any]],
        invalidate_cache: bool = True
    ) -> bool:
        """
        æ‰¹é‡æ›´æ–°æ¨¡å‹æŒ‡æ ‡
        """
        if not updates:
            return True

        # æ‰§è¡Œæ‰¹é‡æ›´æ–°
        success = await async_db_service.batch_update_model_provider_metrics(updates)
        
        if success and invalidate_cache:
            # æ¸…ç†ç›¸å…³ç¼“å­˜
            await self._invalidate_cache_pattern("models:*")
            await self._invalidate_cache_pattern("performance:*")
            logger.info(f"ğŸ§¹ Invalidated cache after batch update of {len(updates)} records")

        return success

    async def batch_health_check(
        self, 
        model_provider_pairs: List[Tuple[str, str]]
    ) -> Dict[str, Any]:
        """
        æ‰¹é‡å¥åº·æ£€æŸ¥
        """
        results = {
            "total_checked": len(model_provider_pairs),
            "healthy": 0,
            "degraded": 0,
            "unhealthy": 0,
            "details": []
        }

        # å¹¶å‘æ‰§è¡Œå¥åº·æ£€æŸ¥
        tasks = []
        for model_name, provider_name in model_provider_pairs:
            task = self._check_model_provider_health(model_name, provider_name)
            tasks.append(task)

        # ç­‰å¾…æ‰€æœ‰æ£€æŸ¥å®Œæˆ
        health_results = await asyncio.gather(*tasks, return_exceptions=True)

        # ç»Ÿè®¡ç»“æœ
        for i, result in enumerate(health_results):
            if isinstance(result, Exception):
                logger.error(f"Health check failed: {result}")
                continue

            results["details"].append(result)
            status = result.get("status", "unhealthy")
            results[status] += 1

        return results

    async def _check_model_provider_health(
        self, 
        model_name: str, 
        provider_name: str
    ) -> Dict[str, Any]:
        """
        æ£€æŸ¥å•ä¸ªæ¨¡å‹-æä¾›å•†çš„å¥åº·çŠ¶æ€
        """
        try:
            # è¿™é‡Œåº”è¯¥å®ç°å®é™…çš„å¥åº·æ£€æŸ¥é€»è¾‘
            # ä¾‹å¦‚å‘é€æµ‹è¯•è¯·æ±‚ã€æ£€æŸ¥å“åº”æ—¶é—´ç­‰
            
            # æ¨¡æ‹Ÿå¥åº·æ£€æŸ¥ï¼ˆå®é™…å®ç°æ—¶éœ€è¦æ ¹æ®å…·ä½“éœ€æ±‚ï¼‰
            start_time = datetime.now()
            
            # æ£€æŸ¥æ•°æ®åº“ä¸­çš„å¥åº·çŠ¶æ€
            model_data = await self.get_model_by_name_enhanced(model_name, True, True)
            if not model_data:
                return {
                    "model_name": model_name,
                    "provider_name": provider_name,
                    "status": "unhealthy",
                    "error": "Model not found"
                }

            # æŸ¥æ‰¾å¯¹åº”çš„æä¾›å•†
            provider_info = None
            for provider in model_data.get("providers", []):
                if provider.get("provider_name") == provider_name:
                    provider_info = provider
                    break

            if not provider_info:
                return {
                    "model_name": model_name,
                    "provider_name": provider_name,
                    "status": "unhealthy",
                    "error": "Provider not found"
                }

            response_time = (datetime.now() - start_time).total_seconds()
            
            # åŸºäºæ€§èƒ½æŒ‡æ ‡åˆ¤æ–­å¥åº·çŠ¶æ€
            overall_score = provider_info.get("overall_score", 0)
            if overall_score >= 0.8:
                status = "healthy"
            elif overall_score >= 0.5:
                status = "degraded"
            else:
                status = "unhealthy"

            return {
                "model_name": model_name,
                "provider_name": provider_name,
                "status": status,
                "response_time": round(response_time, 3),
                "overall_score": overall_score,
                "checked_at": datetime.utcnow().isoformat()
            }

        except Exception as e:
            return {
                "model_name": model_name,
                "provider_name": provider_name,
                "status": "unhealthy",
                "error": str(e),
                "checked_at": datetime.utcnow().isoformat()
            }

    # ==================== ç»Ÿè®¡å’Œç›‘æ§ ====================

    async def get_service_statistics(self) -> Dict[str, Any]:
        """
        è·å–æœåŠ¡ç»Ÿè®¡ä¿¡æ¯
        """
        db_stats = await async_db_service.get_database_statistics()
        
        # Redisç»Ÿè®¡
        redis_stats = {}
        if self.redis_client:
            try:
                info = await self.redis_client.info()
                redis_stats = {
                    "connected_clients": info.get("connected_clients", 0),
                    "used_memory_human": info.get("used_memory_human", "0B"),
                    "keyspace_hits": info.get("keyspace_hits", 0),
                    "keyspace_misses": info.get("keyspace_misses", 0),
                }
            except Exception as e:
                redis_stats = {"error": str(e)}

        # è®¡ç®—ç¼“å­˜æ•ˆç‡
        cache_total = self.performance_metrics["cache_hits"] + self.performance_metrics["cache_misses"]
        cache_hit_rate = (
            self.performance_metrics["cache_hits"] / cache_total * 100
            if cache_total > 0 else 0
        )

        return {
            "database": db_stats,
            "redis": redis_stats,
            "service_performance": {
                **self.performance_metrics,
                "cache_hit_rate": round(cache_hit_rate, 2),
                "cache_enabled": self.cache_enabled,
            },
            "timestamp": datetime.utcnow().isoformat(),
        }

    async def clear_all_cache(self):
        """æ¸…ç†æ‰€æœ‰ç¼“å­˜"""
        if self.redis_client:
            try:
                await self.redis_client.flushdb()
                logger.info("ğŸ§¹ All cache cleared")
            except Exception as e:
                logger.error(f"Failed to clear cache: {e}")

        # åŒæ—¶æ¸…ç†æ•°æ®åº“æœåŠ¡çš„ç¼“å­˜
        await async_db_service.clear_cache()


# å…¨å±€å¢å¼ºæ¨¡å‹æœåŠ¡å®ä¾‹
enhanced_model_service = EnhancedModelService()
