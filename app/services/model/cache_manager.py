"""
æ¨¡å‹ç¼“å­˜ç®¡ç†æ¨¡å—
æä¾›æ¨¡å‹åˆ—è¡¨çš„ç¼“å­˜åŠŸèƒ½ï¼Œæå‡APIå“åº”æ€§èƒ½
"""

import time
from typing import Dict, Any, Optional, Tuple
from app.utils.logging_config import get_factory_logger

logger = get_factory_logger()


class ModelsCacheManager:
    """æ¨¡å‹ç¼“å­˜ç®¡ç†å™¨"""

    def __init__(self, ttl: int = 300):  # å¢åŠ åˆ°5åˆ†é’Ÿ
        """
        åˆå§‹åŒ–ç¼“å­˜ç®¡ç†å™¨

        Args:
            ttl: ç¼“å­˜ç”Ÿå­˜æ—¶é—´ï¼ˆç§’ï¼‰ï¼Œé»˜è®¤300ç§’ï¼ˆ5åˆ†é’Ÿï¼‰
        """
        self._models_cache: Dict[str, Any] = {}
        self._cache_timestamp: float = 0
        self._cache_ttl: int = ttl
        self._cache_hits: int = 0
        self._cache_misses: int = 0
        self._is_prewarmed: bool = False  # ç¼“å­˜é¢„çƒ­æ ‡å¿—

    def get_cached_models(self) -> Tuple[Optional[Dict[str, Any]], bool]:
        """
        è·å–ç¼“å­˜çš„æ¨¡å‹åˆ—è¡¨

        Returns:
            (cached_data, is_cached): ç¼“å­˜æ•°æ®å’Œæ˜¯å¦å‘½ä¸­ç¼“å­˜çš„å…ƒç»„
        """
        current_time = time.time()

        if (
            current_time - self._cache_timestamp < self._cache_ttl
            and self._models_cache
        ):
            self._cache_hits += 1
            logger.debug(f"âœ… Cache hit #{self._cache_hits}")
            return self._models_cache, True

        self._cache_misses += 1
        logger.debug(f"âŒ Cache miss #{self._cache_misses}")
        return None, False

    def set_cached_models(self, models_data: Dict[str, Any]) -> None:
        """
        è®¾ç½®æ¨¡å‹åˆ—è¡¨ç¼“å­˜

        Args:
            models_data: è¦ç¼“å­˜çš„æ¨¡å‹æ•°æ®
        """
        self._models_cache = models_data
        self._cache_timestamp = time.time()
        logger.debug(f"ğŸ’¾ Cache updated with {len(models_data.get('data', []))} models")

    def clear_cache(self) -> None:
        """æ¸…ç†æ¨¡å‹åˆ—è¡¨ç¼“å­˜"""
        self._models_cache = {}
        self._cache_timestamp = 0
        self._is_prewarmed = False
        logger.info("ğŸ§¹ Models cache cleared")

    def prewarm_cache(self, models_data: Dict[str, Any]) -> None:
        """
        é¢„çƒ­ç¼“å­˜ï¼Œåœ¨åº”ç”¨å¯åŠ¨æ—¶é¢„åŠ è½½æ•°æ®

        Args:
            models_data: è¦é¢„åŠ è½½çš„æ¨¡å‹æ•°æ®
        """
        self._models_cache = models_data
        self._cache_timestamp = time.time()
        self._is_prewarmed = True
        logger.info(
            f"ğŸ”¥ Cache prewarmed with {len(models_data.get('data', []))} models"
        )

    def is_prewarmed(self) -> bool:
        """æ£€æŸ¥ç¼“å­˜æ˜¯å¦å·²é¢„çƒ­"""
        return self._is_prewarmed

    def get_cache_stats(self) -> Dict[str, Any]:
        """
        è·å–ç¼“å­˜ç»Ÿè®¡ä¿¡æ¯

        Returns:
            ç¼“å­˜ç»Ÿè®¡ä¿¡æ¯å­—å…¸
        """
        total_requests = self._cache_hits + self._cache_misses
        hit_rate = (
            (self._cache_hits / total_requests * 100) if total_requests > 0 else 0
        )

        return {
            "cache_hits": self._cache_hits,
            "cache_misses": self._cache_misses,
            "total_requests": total_requests,
            "hit_rate": round(hit_rate, 2),
            "cache_size": len(self._models_cache),
            "last_update": self._cache_timestamp,
            "ttl": self._cache_ttl,
            "is_valid": time.time() - self._cache_timestamp < self._cache_ttl,
        }

    def is_cache_valid(self) -> bool:
        """
        æ£€æŸ¥ç¼“å­˜æ˜¯å¦æœ‰æ•ˆ

        Returns:
            ç¼“å­˜æ˜¯å¦æœ‰æ•ˆ
        """
        return time.time() - self._cache_timestamp < self._cache_ttl


# å…¨å±€ç¼“å­˜ç®¡ç†å™¨å®ä¾‹
models_cache = ModelsCacheManager()
