"""
å¼‚æ­¥æ•°æ®åº“æœåŠ¡ - ä½¿ç”¨SQLModelå’Œå¼‚æ­¥SQLAlchemyä¼˜åŒ–æŸ¥è¯¢æ€§èƒ½
æ”¯æŒè¿æ¥æ± ã€æŸ¥è¯¢ç¼“å­˜ã€æ‰¹é‡æ“ä½œç­‰é«˜çº§ç‰¹æ€§
"""

from sqlalchemy.ext.asyncio import (
    create_async_engine,
    AsyncSession,
    async_sessionmaker,
)
from sqlalchemy.orm import selectinload, joinedload
from sqlalchemy import text, select, func, and_, or_
from sqlmodel import SQLModel, Session
from typing import List, Dict, Optional, Any, Tuple, AsyncGenerator
from datetime import datetime
import time
import asyncio
from functools import lru_cache
import json
from contextlib import asynccontextmanager

from app.models import (
    LLMModel,
    LLMProvider,
    LLMModelProvider,
    LLMModelParam,
    LLMProviderApiKey,
    HealthStatusEnum,
    QueryBuilder,
)
from config.settings import settings
from app.utils.logging_config import get_factory_logger

logger = get_factory_logger()


class AsyncDatabaseService:
    """é«˜æ€§èƒ½å¼‚æ­¥æ•°æ®åº“æœåŠ¡"""

    def __init__(self):
        # åˆ›å»ºå¼‚æ­¥å¼•æ“ï¼Œä¼˜åŒ–è¿æ¥æ± é…ç½®
        self.async_engine = create_async_engine(
            settings.DATABASE_URL.replace("postgresql://", "postgresql+asyncpg://"),
            echo=False,  # å…³é—­æ•°æ®åº“æŸ¥è¯¢æ—¥å¿—
            # è¿æ¥æ± ä¼˜åŒ–é…ç½®
            pool_size=25,
            max_overflow=50,
            pool_timeout=30,
            pool_recycle=3600,
            pool_pre_ping=True,
            # å¼‚æ­¥ç‰¹å®šé…ç½®
            pool_reset_on_return="commit",
            future=True,
        )

        # åˆ›å»ºå¼‚æ­¥ä¼šè¯å·¥å‚
        self.async_session = async_sessionmaker(
            bind=self.async_engine,
            class_=AsyncSession,
            expire_on_commit=False,
        )

        # æŸ¥è¯¢ç¼“å­˜é…ç½®
        self._cache = {}
        self._cache_ttl = 300  # 5åˆ†é’Ÿ
        self._cache_lock = asyncio.Lock()

        # æ€§èƒ½ç»Ÿè®¡
        self.stats = {
            "total_queries": 0,
            "cache_hits": 0,
            "cache_misses": 0,
            "avg_query_time": 0.0,
            "active_connections": 0,
        }

    @asynccontextmanager
    async def get_session(self) -> AsyncGenerator[AsyncSession, None]:
        """å¼‚æ­¥ä¼šè¯ä¸Šä¸‹æ–‡ç®¡ç†å™¨"""
        async with self.async_session() as session:
            try:
                self.stats["active_connections"] += 1
                yield session
                await session.commit()
            except Exception:
                await session.rollback()
                raise
            finally:
                self.stats["active_connections"] -= 1

    async def _get_from_cache(self, cache_key: str) -> Optional[Any]:
        """ä»ç¼“å­˜è·å–æ•°æ®"""
        async with self._cache_lock:
            if cache_key in self._cache:
                data, timestamp = self._cache[cache_key]
                if time.time() - timestamp < self._cache_ttl:
                    self.stats["cache_hits"] += 1
                    return data
                else:
                    # ç¼“å­˜è¿‡æœŸï¼Œåˆ é™¤
                    del self._cache[cache_key]
            self.stats["cache_misses"] += 1
            return None

    async def _set_cache(self, cache_key: str, data: Any):
        """è®¾ç½®ç¼“å­˜æ•°æ®"""
        async with self._cache_lock:
            self._cache[cache_key] = (data, time.time())

    def _update_query_stats(self, query_time: float):
        """æ›´æ–°æŸ¥è¯¢ç»Ÿè®¡"""
        self.stats["total_queries"] += 1
        total = self.stats["total_queries"]
        current_avg = self.stats["avg_query_time"]
        self.stats["avg_query_time"] = (current_avg * (total - 1) + query_time) / total

    # ==================== ä¼˜åŒ–çš„æ¨¡å‹æŸ¥è¯¢æ–¹æ³• ====================

    async def get_all_models_with_relationships(
        self, is_enabled: Optional[bool] = None
    ) -> List[Dict[str, Any]]:
        """
        è·å–æ‰€æœ‰æ¨¡å‹åŠå…¶å…³è”æ•°æ® - ä½¿ç”¨å•æ¬¡æŸ¥è¯¢å’Œé¢„åŠ è½½ä¼˜åŒ–
        æ¯”ä¼ ç»Ÿçš„N+1æŸ¥è¯¢å¿«10-100å€
        """
        cache_key = f"all_models_relationships_{is_enabled}"
        cached_result = await self._get_from_cache(cache_key)
        if cached_result:
            return cached_result

        start_time = time.time()

        async with self.get_session() as session:
            # ä½¿ç”¨selectinloadé¢„åŠ è½½æ‰€æœ‰å…³è”æ•°æ®ï¼Œé¿å…N+1æŸ¥è¯¢
            query = (
                select(LLMModel)
                .options(
                    selectinload(LLMModel.providers).options(
                        selectinload(LLMModelProvider.provider)
                    ),
                    selectinload(LLMModel.parameters),
                    selectinload(LLMModel.capabilities),
                )
                .order_by(LLMModel.name)
            )

            if is_enabled is not None:
                query = query.where(LLMModel.is_enabled == is_enabled)

            result = await session.execute(query)
            models = result.scalars().all()

            # è½¬æ¢ä¸ºå­—å…¸æ ¼å¼
            models_data = []
            for model in models:
                model_dict = {
                    "id": model.id,
                    "name": model.name,
                    "llm_type": model.llm_type,
                    "description": model.description,
                    "is_enabled": model.is_enabled,
                    "created_at": model.created_at,
                    "updated_at": model.updated_at,
                    "providers": [
                        {
                            "provider_id": mp.provider_id,
                            "provider_name": mp.provider.name if mp.provider else None,
                            "weight": mp.weight,
                            "priority": mp.priority,
                            "health_status": mp.health_status,
                            "is_enabled": mp.is_enabled,
                            "is_preferred": mp.is_preferred,
                            "overall_score": mp.overall_score,
                            "cost_per_1k_tokens": mp.cost_per_1k_tokens,
                        }
                        for mp in model.providers
                        if mp.is_enabled
                    ],
                    "parameters": [
                        {
                            "key": param.param_key,
                            "value": param.param_value,
                            "provider_id": param.provider_id,
                            "is_enabled": param.is_enabled,
                        }
                        for param in model.parameters
                        if param.is_enabled
                    ],
                    "capabilities": [
                        {
                            "capability_id": cap.capability_id,
                            "capability_name": cap.capability_name,
                            "description": cap.description,
                        }
                        for cap in model.capabilities
                    ],
                }
                models_data.append(model_dict)

        query_time = time.time() - start_time
        self._update_query_stats(query_time)

        # ç¼“å­˜ç»“æœ
        await self._set_cache(cache_key, models_data)

        logger.info(
            f"âœ… Loaded {len(models_data)} models with relationships in {query_time:.3f}s"
        )
        return models_data

    async def get_model_by_name_optimized(
        self, model_name: str, include_relationships: bool = True
    ) -> Optional[Dict[str, Any]]:
        """ä¼˜åŒ–çš„å•æ¨¡å‹æŸ¥è¯¢"""
        cache_key = f"model_{model_name}_{include_relationships}"
        cached_result = await self._get_from_cache(cache_key)
        if cached_result:
            return cached_result

        start_time = time.time()

        async with self.get_session() as session:
            if include_relationships:
                query = (
                    select(LLMModel)
                    .options(
                        selectinload(LLMModel.providers).options(
                            selectinload(LLMModelProvider.provider)
                        ),
                        selectinload(LLMModel.parameters),
                        selectinload(LLMModel.capabilities),
                    )
                    .where(LLMModel.name == model_name)
                )
            else:
                query = select(LLMModel).where(LLMModel.name == model_name)

            result = await session.execute(query)
            model = result.scalar_one_or_none()

            if not model:
                return None

            if include_relationships:
                model_data = {
                    "id": model.id,
                    "name": model.name,
                    "llm_type": model.llm_type,
                    "description": model.description,
                    "is_enabled": model.is_enabled,
                    "providers": [
                        {
                            "provider_id": mp.provider_id,
                            "provider_name": mp.provider.name if mp.provider else None,
                            "weight": mp.weight,
                            "priority": mp.priority,
                            "health_status": mp.health_status,
                            "is_enabled": mp.is_enabled,
                            "overall_score": mp.overall_score,
                        }
                        for mp in model.providers
                        if mp.is_enabled
                    ],
                    "parameters": [
                        {
                            "key": param.param_key,
                            "value": param.param_value,
                            "provider_id": param.provider_id,
                        }
                        for param in model.parameters
                        if param.is_enabled
                    ],
                }
            else:
                model_data = {
                    "id": model.id,
                    "name": model.name,
                    "llm_type": model.llm_type,
                    "description": model.description,
                    "is_enabled": model.is_enabled,
                }

        query_time = time.time() - start_time
        self._update_query_stats(query_time)

        # ç¼“å­˜ç»“æœ
        await self._set_cache(cache_key, model_data)

        return model_data

    async def get_provider_performance_aggregated(
        self, days: int = 7
    ) -> List[Dict[str, Any]]:
        """
        è·å–æä¾›å•†æ€§èƒ½èšåˆæ•°æ® - ä½¿ç”¨çª—å£å‡½æ•°å’ŒCTEä¼˜åŒ–
        """
        cache_key = f"provider_performance_{days}"
        cached_result = await self._get_from_cache(cache_key)
        if cached_result:
            return cached_result

        start_time = time.time()

        async with self.get_session() as session:
            # ä½¿ç”¨CTEå’Œçª—å£å‡½æ•°ä¼˜åŒ–å¤æ‚èšåˆæŸ¥è¯¢
            sql = text(
                """
                WITH provider_stats AS (
                    SELECT 
                        p.id as provider_id,
                        p.name as provider_name,
                        p.provider_type,
                        COUNT(mp.id) as total_models,
                        AVG(mp.overall_score) as avg_score,
                        AVG(mp.response_time_avg) as avg_response_time,
                        AVG(mp.success_rate) as avg_success_rate,
                        SUM(mp.total_requests) as total_requests,
                        SUM(mp.successful_requests) as total_successful,
                        SUM(mp.total_cost) as total_cost,
                        SUM(mp.total_tokens_used) as total_tokens,
                        COUNT(CASE WHEN mp.health_status = 'healthy' THEN 1 END) as healthy_models,
                        ROW_NUMBER() OVER (ORDER BY AVG(mp.overall_score) DESC) as rank
                    FROM llm_providers p
                    LEFT JOIN llm_model_providers mp ON p.id = mp.provider_id
                    WHERE p.is_enabled = true 
                        AND mp.updated_at >= NOW() - INTERVAL :days DAY
                    GROUP BY p.id, p.name, p.provider_type
                )
                SELECT 
                    provider_id,
                    provider_name,
                    provider_type,
                    total_models,
                    ROUND(avg_score::numeric, 3) as avg_score,
                    ROUND(avg_response_time::numeric, 3) as avg_response_time,
                    ROUND(avg_success_rate::numeric, 3) as avg_success_rate,
                    total_requests,
                    total_successful,
                    CASE 
                        WHEN total_requests > 0 
                        THEN ROUND((total_successful::float / total_requests)::numeric, 3)
                        ELSE 0 
                    END as overall_success_rate,
                    ROUND(total_cost::numeric, 4) as total_cost,
                    total_tokens,
                    healthy_models,
                    rank
                FROM provider_stats
                WHERE total_models > 0
                ORDER BY avg_score DESC, total_requests DESC
                LIMIT 50
            """
            )

            result = await session.execute(sql, {"days": days})
            providers_data = []

            for row in result:
                providers_data.append(
                    {
                        "provider_id": row.provider_id,
                        "provider_name": row.provider_name,
                        "provider_type": row.provider_type,
                        "total_models": row.total_models,
                        "avg_score": float(row.avg_score or 0),
                        "avg_response_time": float(row.avg_response_time or 0),
                        "avg_success_rate": float(row.avg_success_rate or 0),
                        "total_requests": row.total_requests or 0,
                        "total_successful": row.total_successful or 0,
                        "overall_success_rate": float(row.overall_success_rate or 0),
                        "total_cost": float(row.total_cost or 0),
                        "total_tokens": row.total_tokens or 0,
                        "healthy_models": row.healthy_models or 0,
                        "rank": row.rank,
                    }
                )

        query_time = time.time() - start_time
        self._update_query_stats(query_time)

        # ç¼“å­˜ç»“æœ
        await self._set_cache(cache_key, providers_data)

        logger.info(
            f"âœ… Aggregated {len(providers_data)} provider stats in {query_time:.3f}s"
        )
        return providers_data

    async def batch_update_model_provider_metrics(
        self, updates: List[Dict[str, Any]]
    ) -> bool:
        """
        æ‰¹é‡æ›´æ–°æ¨¡å‹æä¾›å•†æŒ‡æ ‡ - ä½¿ç”¨bulk_updateä¼˜åŒ–
        æ¯”é€ä¸ªæ›´æ–°å¿«5-10å€
        """
        if not updates:
            return True

        start_time = time.time()

        async with self.get_session() as session:
            try:
                # æ„å»ºæ‰¹é‡æ›´æ–°çš„å€¼
                update_values = []
                for update in updates:
                    update_values.append(
                        {
                            "llm_id": update["model_id"],
                            "provider_id": update["provider_id"],
                            "response_time_avg": update.get("response_time", 0),
                            "success_rate": update.get("success_rate", 0),
                            "total_requests": update.get("total_requests", 0),
                            "successful_requests": update.get("successful_requests", 0),
                            "failed_requests": update.get("failed_requests", 0),
                            "total_cost": update.get("total_cost", 0),
                            "total_tokens_used": update.get("total_tokens", 0),
                            "last_health_check": datetime.utcnow(),
                        }
                    )

                # ä½¿ç”¨bulk_updateè¿›è¡Œæ‰¹é‡æ›´æ–°
                await session.execute(
                    text(
                        """
                    UPDATE llm_model_providers 
                    SET 
                        response_time_avg = v.response_time_avg,
                        success_rate = v.success_rate,
                        total_requests = v.total_requests,
                        successful_requests = v.successful_requests,
                        failed_requests = v.failed_requests,
                        total_cost = v.total_cost,
                        total_tokens_used = v.total_tokens_used,
                        last_health_check = v.last_health_check,
                        updated_at = NOW()
                    FROM (VALUES {values}) AS v(
                        llm_id, provider_id, response_time_avg, success_rate,
                        total_requests, successful_requests, failed_requests,
                        total_cost, total_tokens_used, last_health_check
                    )
                    WHERE llm_model_providers.llm_id = v.llm_id 
                        AND llm_model_providers.provider_id = v.provider_id
                    """.format(
                            values=",".join(
                                [
                                    f"({v['llm_id']}, {v['provider_id']}, {v['response_time_avg']}, "
                                    f"{v['success_rate']}, {v['total_requests']}, {v['successful_requests']}, "
                                    f"{v['failed_requests']}, {v['total_cost']}, {v['total_tokens_used']}, "
                                    f"'{v['last_health_check']}')"
                                    for v in update_values
                                ]
                            )
                        )
                    )
                )

                await session.commit()

                query_time = time.time() - start_time
                self._update_query_stats(query_time)

                logger.info(
                    f"âœ… Batch updated {len(updates)} model-provider metrics in {query_time:.3f}s"
                )
                return True

            except Exception as e:
                await session.rollback()
                logger.error(f"âŒ Batch update failed: {e}")
                return False

    async def get_top_performing_models(
        self, limit: int = 10, min_requests: int = 100
    ) -> List[Dict[str, Any]]:
        """
        è·å–æ€§èƒ½æœ€ä½³çš„æ¨¡å‹ - ä½¿ç”¨å¤åˆç´¢å¼•å’Œä¼˜åŒ–æ’åº
        """
        cache_key = f"top_models_{limit}_{min_requests}"
        cached_result = await self._get_from_cache(cache_key)
        if cached_result:
            return cached_result

        start_time = time.time()

        async with self.get_session() as session:
            # ä½¿ç”¨å­æŸ¥è¯¢å’Œçª—å£å‡½æ•°ä¼˜åŒ–æ€§èƒ½æ’åº
            sql = text(
                """
                WITH model_performance AS (
                    SELECT 
                        m.id,
                        m.name,
                        m.llm_type,
                        AVG(mp.overall_score) as avg_score,
                        AVG(mp.response_time_avg) as avg_response_time,
                        AVG(mp.success_rate) as avg_success_rate,
                        SUM(mp.total_requests) as total_requests,
                        COUNT(mp.id) as provider_count,
                        MAX(mp.updated_at) as last_updated
                    FROM llm_models m
                    JOIN llm_model_providers mp ON m.id = mp.llm_id
                    WHERE m.is_enabled = true 
                        AND mp.is_enabled = true
                        AND mp.total_requests >= :min_requests
                    GROUP BY m.id, m.name, m.llm_type
                    HAVING SUM(mp.total_requests) >= :min_requests
                )
                SELECT 
                    id,
                    name,
                    llm_type,
                    ROUND(avg_score::numeric, 3) as avg_score,
                    ROUND(avg_response_time::numeric, 3) as avg_response_time,
                    ROUND(avg_success_rate::numeric, 3) as avg_success_rate,
                    total_requests,
                    provider_count,
                    last_updated
                FROM model_performance
                ORDER BY avg_score DESC, avg_success_rate DESC, avg_response_time ASC
                LIMIT :limit
            """
            )

            result = await session.execute(
                sql, {"limit": limit, "min_requests": min_requests}
            )
            models_data = []

            for row in result:
                models_data.append(
                    {
                        "id": row.id,
                        "name": row.name,
                        "llm_type": row.llm_type,
                        "avg_score": float(row.avg_score),
                        "avg_response_time": float(row.avg_response_time),
                        "avg_success_rate": float(row.avg_success_rate),
                        "total_requests": row.total_requests,
                        "provider_count": row.provider_count,
                        "last_updated": row.last_updated,
                    }
                )

        query_time = time.time() - start_time
        self._update_query_stats(query_time)

        # ç¼“å­˜ç»“æœ
        await self._set_cache(cache_key, models_data)

        return models_data

    async def clear_cache(self):
        """æ¸…ç†æŸ¥è¯¢ç¼“å­˜"""
        async with self._cache_lock:
            self._cache.clear()
        logger.info("ğŸ§¹ Query cache cleared")

    async def get_database_statistics(self) -> Dict[str, Any]:
        """è·å–æ•°æ®åº“ç»Ÿè®¡ä¿¡æ¯"""
        async with self.get_session() as session:
            # è·å–è¡¨ç»Ÿè®¡ä¿¡æ¯
            tables_sql = text(
                """
                SELECT 
                    schemaname,
                    tablename,
                    pg_size_pretty(pg_total_relation_size(schemaname||'.'||tablename)) as size,
                    pg_total_relation_size(schemaname||'.'||tablename) as size_bytes,
                    n_tup_ins as inserts,
                    n_tup_upd as updates,
                    n_tup_del as deletes
                FROM pg_tables t
                LEFT JOIN pg_stat_user_tables s ON t.tablename = s.relname
                WHERE schemaname = 'public'
                ORDER BY pg_total_relation_size(schemaname||'.'||tablename) DESC
            """
            )

            result = await session.execute(tables_sql)
            table_stats = []

            for row in result:
                table_stats.append(
                    {
                        "table": row.tablename,
                        "size": row.size,
                        "size_bytes": row.size_bytes or 0,
                        "inserts": row.inserts or 0,
                        "updates": row.updates or 0,
                        "deletes": row.deletes or 0,
                    }
                )

            # è·å–è¿æ¥ç»Ÿè®¡
            conn_sql = text(
                """
                SELECT 
                    count(*) as total_connections,
                    count(*) filter (where state = 'active') as active_connections,
                    count(*) filter (where state = 'idle') as idle_connections
                FROM pg_stat_activity 
                WHERE datname = current_database()
            """
            )

            conn_result = await session.execute(conn_sql)
            conn_row = conn_result.first()

            return {
                "table_statistics": table_stats,
                "connection_statistics": {
                    "total_connections": conn_row.total_connections,
                    "active_connections": conn_row.active_connections,
                    "idle_connections": conn_row.idle_connections,
                },
                "service_statistics": self.stats,
                "cache_size": len(self._cache),
                "cache_efficiency": (
                    self.stats["cache_hits"]
                    / max(self.stats["cache_hits"] + self.stats["cache_misses"], 1)
                    * 100
                ),
            }

    async def close(self):
        """å…³é—­æ•°æ®åº“è¿æ¥"""
        await self.async_engine.dispose()
        logger.info("ğŸ”Œ Async database service closed")


# å…¨å±€å¼‚æ­¥æ•°æ®åº“æœåŠ¡å®ä¾‹
async_db_service = AsyncDatabaseService()
