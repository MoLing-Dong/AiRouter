"""
æ€§èƒ½ç›‘æ§ç³»ç»Ÿ

å®æ—¶ç›‘æ§ç³»ç»Ÿæ€§èƒ½ï¼Œæ”¶é›†å…³é”®æŒ‡æ ‡ï¼Œæä¾›æ€§èƒ½åˆ†æå’Œä¼˜åŒ–å»ºè®®
"""

import time
import asyncio
import psutil
import threading
from typing import Dict, List, Any, Optional, Callable
from dataclasses import dataclass, field
from datetime import datetime, timedelta
from collections import deque, defaultdict
import statistics
from prometheus_client import Counter, Histogram, Gauge, Summary
from app.utils.logging_config import get_factory_logger

logger = get_factory_logger()


@dataclass
class PerformanceMetric:
    """æ€§èƒ½æŒ‡æ ‡æ•°æ®"""

    timestamp: float
    value: float
    tags: Dict[str, str] = field(default_factory=dict)


@dataclass
class PerformanceAlert:
    """æ€§èƒ½å‘Šè­¦"""

    timestamp: float
    metric_name: str
    current_value: float
    threshold: float
    severity: str  # low, medium, high, critical
    message: str


class PerformanceMonitor:
    """æ€§èƒ½ç›‘æ§å™¨"""

    def __init__(self):
        # æŒ‡æ ‡å­˜å‚¨
        self.metrics: Dict[str, deque] = defaultdict(lambda: deque(maxlen=10000))
        self.alerts: List[PerformanceAlert] = []

        # ç›‘æ§é…ç½®
        self.monitoring_enabled = True
        self.collection_interval = 1.0  # 1ç§’æ”¶é›†ä¸€æ¬¡
        self.alert_thresholds = {
            "cpu_usage": 80.0,
            "memory_usage": 85.0,
            "disk_usage": 90.0,
            "response_time": 5.0,
            "error_rate": 5.0,
        }

        # ç›‘æ§ä»»åŠ¡
        self._monitoring_task: Optional[asyncio.Task] = None
        self._stop_event = threading.Event()

        # PrometheusæŒ‡æ ‡
        self._init_prometheus_metrics()

        # æ€§èƒ½åˆ†æå™¨
        self.performance_analyzer = PerformanceAnalyzer()

        # å‘Šè­¦å¤„ç†å™¨
        self.alert_handler = AlertHandler()

    def _init_prometheus_metrics(self):
        """åˆå§‹åŒ–PrometheusæŒ‡æ ‡"""
        # ç³»ç»ŸæŒ‡æ ‡
        self.cpu_gauge = Gauge("system_cpu_usage_percent", "CPU usage percentage")
        self.memory_gauge = Gauge(
            "system_memory_usage_percent", "Memory usage percentage"
        )
        self.disk_gauge = Gauge("system_disk_usage_percent", "Disk usage percentage")

        # åº”ç”¨æŒ‡æ ‡
        self.request_counter = Counter(
            "app_requests_total", "Total requests", ["endpoint", "method"]
        )
        self.response_time_histogram = Histogram(
            "app_response_time_seconds", "Response time in seconds", ["endpoint"]
        )
        self.error_counter = Counter(
            "app_errors_total", "Total errors", ["endpoint", "error_type"]
        )

        # ä¸šåŠ¡æŒ‡æ ‡
        self.active_connections_gauge = Gauge(
            "app_active_connections", "Active connections"
        )
        self.queue_size_gauge = Gauge("app_queue_size", "Queue size")
        self.cache_hit_rate_gauge = Gauge("app_cache_hit_rate", "Cache hit rate")

    async def start(self):
        """å¯åŠ¨æ€§èƒ½ç›‘æ§"""
        if self._monitoring_task is None:
            self._monitoring_task = asyncio.create_task(self._monitoring_loop())
            logger.info("ğŸš€ Performance monitoring started")

    async def stop(self):
        """åœæ­¢æ€§èƒ½ç›‘æ§"""
        self._stop_event.set()
        if self._monitoring_task:
            self._monitoring_task.cancel()
            try:
                await self._monitoring_task
            except asyncio.CancelledError:
                pass
            self._monitoring_task = None
        logger.info("ğŸ›‘ Performance monitoring stopped")

    async def _monitoring_loop(self):
        """ç›‘æ§å¾ªç¯"""
        while not self._stop_event.is_set():
            try:
                # æ”¶é›†ç³»ç»ŸæŒ‡æ ‡
                await self._collect_system_metrics()

                # æ”¶é›†åº”ç”¨æŒ‡æ ‡
                await self._collect_application_metrics()

                # åˆ†ææ€§èƒ½
                await self._analyze_performance()

                # æ£€æŸ¥å‘Šè­¦
                await self._check_alerts()

                await asyncio.sleep(self.collection_interval)

            except Exception as e:
                logger.error(f"Performance monitoring error: {e}")
                await asyncio.sleep(5)

    async def _collect_system_metrics(self):
        """æ”¶é›†ç³»ç»ŸæŒ‡æ ‡"""
        try:
            # CPUä½¿ç”¨ç‡
            cpu_percent = psutil.cpu_percent(interval=0.1)
            self._record_metric("cpu_usage", cpu_percent, {"type": "system"})
            self.cpu_gauge.set(cpu_percent)

            # å†…å­˜ä½¿ç”¨ç‡
            memory = psutil.virtual_memory()
            memory_percent = memory.percent
            self._record_metric("memory_usage", memory_percent, {"type": "system"})
            self.memory_gauge.set(memory_percent)

            # ç£ç›˜ä½¿ç”¨ç‡
            disk = psutil.disk_usage("/")
            disk_percent = (disk.used / disk.total) * 100
            self._record_metric("disk_usage", disk_percent, {"type": "system"})
            self.disk_gauge.set(disk_percent)

            # ç½‘ç»œIO
            net_io = psutil.net_io_counters()
            self._record_metric(
                "network_bytes_sent", net_io.bytes_sent, {"type": "system"}
            )
            self._record_metric(
                "network_bytes_recv", net_io.bytes_recv, {"type": "system"}
            )

            # è¿›ç¨‹ä¿¡æ¯
            process = psutil.Process()
            self._record_metric(
                "process_cpu_percent", process.cpu_percent(), {"type": "process"}
            )
            self._record_metric(
                "process_memory_percent", process.memory_percent(), {"type": "process"}
            )

        except Exception as e:
            logger.error(f"Failed to collect system metrics: {e}")

    async def _collect_application_metrics(self):
        """æ”¶é›†åº”ç”¨æŒ‡æ ‡"""
        try:
            # è¿™é‡Œæ”¶é›†åº”ç”¨ç‰¹å®šçš„æŒ‡æ ‡
            # ä¾‹å¦‚ï¼šè¿æ¥æ•°ã€é˜Ÿåˆ—å¤§å°ã€ç¼“å­˜å‘½ä¸­ç‡ç­‰

            # æ¨¡æ‹Ÿä¸€äº›åº”ç”¨æŒ‡æ ‡
            active_connections = len(asyncio.all_tasks())
            self._record_metric(
                "active_connections", active_connections, {"type": "application"}
            )
            self.active_connections_gauge.set(active_connections)

            # é˜Ÿåˆ—å¤§å°ï¼ˆå¦‚æœæœ‰çš„è¯ï¼‰
            queue_size = 0  # è¿™é‡Œåº”è¯¥ä»å®é™…çš„é˜Ÿåˆ—è·å–
            self._record_metric("queue_size", queue_size, {"type": "application"})
            self.queue_size_gauge.set(queue_size)

        except Exception as e:
            logger.error(f"Failed to collect application metrics: {e}")

    def _record_metric(self, name: str, value: float, tags: Dict[str, str]):
        """è®°å½•æŒ‡æ ‡"""
        metric = PerformanceMetric(timestamp=time.time(), value=value, tags=tags)
        self.metrics[name].append(metric)

    async def _analyze_performance(self):
        """åˆ†ææ€§èƒ½"""
        try:
            analysis = await self.performance_analyzer.analyze(self.metrics)

            # è®°å½•åˆ†æç»“æœ
            for metric_name, result in analysis.items():
                if "trend" in result:
                    self._record_metric(
                        f"{metric_name}_trend", result["trend"], {"type": "analysis"}
                    )

                if "anomaly_score" in result:
                    self._record_metric(
                        f"{metric_name}_anomaly",
                        result["anomaly_score"],
                        {"type": "analysis"},
                    )

        except Exception as e:
            logger.error(f"Performance analysis failed: {e}")

    async def _check_alerts(self):
        """æ£€æŸ¥å‘Šè­¦"""
        try:
            for metric_name, threshold in self.alert_thresholds.items():
                if metric_name in self.metrics and self.metrics[metric_name]:
                    latest_metric = self.metrics[metric_name][-1]

                    if latest_metric.value > threshold:
                        alert = PerformanceAlert(
                            timestamp=latest_metric.timestamp,
                            metric_name=metric_name,
                            current_value=latest_metric.value,
                            threshold=threshold,
                            severity=self._get_severity(latest_metric.value, threshold),
                            message=f"{metric_name} exceeded threshold: {latest_metric.value:.2f} > {threshold:.2f}",
                        )

                        await self.alert_handler.handle_alert(alert)
                        self.alerts.append(alert)

        except Exception as e:
            logger.error(f"Alert checking failed: {e}")

    def _get_severity(self, value: float, threshold: float) -> str:
        """è·å–å‘Šè­¦ä¸¥é‡ç¨‹åº¦"""
        ratio = value / threshold
        if ratio >= 2.0:
            return "critical"
        elif ratio >= 1.5:
            return "high"
        elif ratio >= 1.2:
            return "medium"
        else:
            return "low"

    def record_request(
        self, endpoint: str, method: str, response_time: float, success: bool
    ):
        """è®°å½•è¯·æ±‚æŒ‡æ ‡"""
        # PrometheusæŒ‡æ ‡
        self.request_counter.labels(endpoint=endpoint, method=method).inc()
        self.response_time_histogram.labels(endpoint=endpoint).observe(response_time)

        if not success:
            self.error_counter.labels(
                endpoint=endpoint, error_type="request_failed"
            ).inc()

        # å†…éƒ¨æŒ‡æ ‡
        self._record_metric(
            "response_time",
            response_time,
            {"endpoint": endpoint, "method": method, "success": str(success)},
        )

        if not success:
            self._record_metric(
                "error_rate", 1.0, {"endpoint": endpoint, "method": method}
            )

    def get_metrics_summary(
        self, metric_name: str, duration: int = 3600
    ) -> Dict[str, Any]:
        """è·å–æŒ‡æ ‡æ‘˜è¦"""
        if metric_name not in self.metrics:
            return {}

        cutoff_time = time.time() - duration
        recent_metrics = [
            m for m in self.metrics[metric_name] if m.timestamp >= cutoff_time
        ]

        if not recent_metrics:
            return {}

        values = [m.value for m in recent_metrics]

        return {
            "count": len(values),
            "min": min(values),
            "max": max(values),
            "mean": statistics.mean(values),
            "median": statistics.median(values),
            "std_dev": statistics.stdev(values) if len(values) > 1 else 0,
            "latest": values[-1] if values else 0,
            "trend": self._calculate_trend(values),
        }

    def _calculate_trend(self, values: List[float]) -> float:
        """è®¡ç®—è¶‹åŠ¿ï¼ˆæ­£å€¼è¡¨ç¤ºä¸Šå‡ï¼Œè´Ÿå€¼è¡¨ç¤ºä¸‹é™ï¼‰"""
        if len(values) < 2:
            return 0.0

        # ä½¿ç”¨çº¿æ€§å›å½’è®¡ç®—è¶‹åŠ¿
        n = len(values)
        x_sum = sum(range(n))
        y_sum = sum(values)
        xy_sum = sum(i * v for i, v in enumerate(values))
        x2_sum = sum(i * i for i in range(n))

        try:
            slope = (n * xy_sum - x_sum * y_sum) / (n * x2_sum - x_sum * x_sum)
            return slope
        except ZeroDivisionError:
            return 0.0

    def get_performance_report(self) -> Dict[str, Any]:
        """è·å–æ€§èƒ½æŠ¥å‘Š"""
        report = {
            "timestamp": datetime.now().isoformat(),
            "system_metrics": {},
            "application_metrics": {},
            "alerts": [],
            "recommendations": [],
        }

        # ç³»ç»ŸæŒ‡æ ‡æ‘˜è¦
        for metric_name in ["cpu_usage", "memory_usage", "disk_usage"]:
            if metric_name in self.metrics:
                report["system_metrics"][metric_name] = self.get_metrics_summary(
                    metric_name, 300
                )  # 5åˆ†é’Ÿ

        # åº”ç”¨æŒ‡æ ‡æ‘˜è¦
        for metric_name in ["response_time", "active_connections", "queue_size"]:
            if metric_name in self.metrics:
                report["application_metrics"][metric_name] = self.get_metrics_summary(
                    metric_name, 300
                )

        # å‘Šè­¦æ‘˜è¦
        recent_alerts = [
            alert
            for alert in self.alerts
            if alert.timestamp >= time.time() - 3600  # 1å°æ—¶å†…çš„å‘Šè­¦
        ]
        report["alerts"] = [
            {
                "timestamp": datetime.fromtimestamp(alert.timestamp).isoformat(),
                "metric": alert.metric_name,
                "severity": alert.severity,
                "message": alert.message,
            }
            for alert in recent_alerts
        ]

        # æ€§èƒ½å»ºè®®
        report["recommendations"] = self._generate_recommendations()

        return report

    def _generate_recommendations(self) -> List[str]:
        """ç”Ÿæˆæ€§èƒ½ä¼˜åŒ–å»ºè®®"""
        recommendations = []

        # CPUä½¿ç”¨ç‡å»ºè®®
        cpu_summary = self.get_metrics_summary("cpu_usage", 300)
        if cpu_summary and cpu_summary.get("mean", 0) > 70:
            recommendations.append("CPUä½¿ç”¨ç‡è¾ƒé«˜ï¼Œå»ºè®®ä¼˜åŒ–ä»£ç æˆ–å¢åŠ CPUèµ„æº")

        # å†…å­˜ä½¿ç”¨ç‡å»ºè®®
        memory_summary = self.get_metrics_summary("memory_usage", 300)
        if memory_summary and memory_summary.get("mean", 0) > 80:
            recommendations.append("å†…å­˜ä½¿ç”¨ç‡è¾ƒé«˜ï¼Œå»ºè®®æ£€æŸ¥å†…å­˜æ³„æ¼æˆ–å¢åŠ å†…å­˜")

        # å“åº”æ—¶é—´å»ºè®®
        response_summary = self.get_metrics_summary("response_time", 300)
        if response_summary and response_summary.get("mean", 0) > 2.0:
            recommendations.append("å“åº”æ—¶é—´è¾ƒé•¿ï¼Œå»ºè®®ä¼˜åŒ–æ•°æ®åº“æŸ¥è¯¢æˆ–å¢åŠ ç¼“å­˜")

        # é”™è¯¯ç‡å»ºè®®
        error_summary = self.get_metrics_summary("error_rate", 300)
        if error_summary and error_summary.get("mean", 0) > 1.0:
            recommendations.append("é”™è¯¯ç‡è¾ƒé«˜ï¼Œå»ºè®®æ£€æŸ¥ç³»ç»Ÿæ—¥å¿—å’Œé”™è¯¯å¤„ç†")

        return recommendations


class PerformanceAnalyzer:
    """æ€§èƒ½åˆ†æå™¨"""

    def __init__(self):
        self.analysis_cache = {}
        self.cache_ttl = 60.0  # ç¼“å­˜60ç§’

    async def analyze(self, metrics: Dict[str, deque]) -> Dict[str, Dict[str, Any]]:
        """åˆ†ææ€§èƒ½æŒ‡æ ‡"""
        analysis = {}

        for metric_name, metric_queue in metrics.items():
            if not metric_queue:
                continue

            # æ£€æŸ¥ç¼“å­˜
            cache_key = f"{metric_name}_{len(metric_queue)}"
            if cache_key in self.analysis_cache:
                cache_entry = self.analysis_cache[cache_key]
                if time.time() - cache_entry["timestamp"] < self.cache_ttl:
                    analysis[metric_name] = cache_entry["data"]
                    continue

            # æ‰§è¡Œåˆ†æ
            result = await self._analyze_metric(metric_name, metric_queue)

            # ç¼“å­˜ç»“æœ
            self.analysis_cache[cache_key] = {"timestamp": time.time(), "data": result}

            analysis[metric_name] = result

        return analysis

    async def _analyze_metric(
        self, metric_name: str, metric_queue: deque
    ) -> Dict[str, Any]:
        """åˆ†æå•ä¸ªæŒ‡æ ‡"""
        if not metric_queue:
            return {}

        values = [m.value for m in metric_queue]
        timestamps = [m.timestamp for m in metric_queue]

        result = {}

        # åŸºç¡€ç»Ÿè®¡
        result["count"] = len(values)
        result["min"] = min(values)
        result["max"] = max(values)
        result["mean"] = statistics.mean(values)
        result["median"] = statistics.median(values)

        # è¶‹åŠ¿åˆ†æ
        if len(values) >= 2:
            result["trend"] = self._calculate_trend(values)
            result["trend_direction"] = (
                "increasing"
                if result["trend"] > 0
                else "decreasing" if result["trend"] < 0 else "stable"
            )

        # å¼‚å¸¸æ£€æµ‹
        if len(values) >= 10:
            result["anomaly_score"] = self._detect_anomalies(values)

        # å‘¨æœŸæ€§åˆ†æ
        if len(timestamps) >= 20:
            result["periodicity"] = self._detect_periodicity(timestamps, values)

        return result

    def _calculate_trend(self, values: List[float]) -> float:
        """è®¡ç®—è¶‹åŠ¿"""
        if len(values) < 2:
            return 0.0

        n = len(values)
        x_sum = sum(range(n))
        y_sum = sum(values)
        xy_sum = sum(i * v for i, v in enumerate(values))
        x2_sum = sum(i * i for i in range(n))

        try:
            slope = (n * xy_sum - x_sum * y_sum) / (n * x2_sum - x_sum * x_sum)
            return slope
        except ZeroDivisionError:
            return 0.0

    def _detect_anomalies(self, values: List[float]) -> float:
        """æ£€æµ‹å¼‚å¸¸å€¼"""
        if len(values) < 10:
            return 0.0

        mean = statistics.mean(values)
        std_dev = statistics.stdev(values) if len(values) > 1 else 0

        if std_dev == 0:
            return 0.0

        # è®¡ç®—Z-score
        z_scores = [abs((v - mean) / std_dev) for v in values]
        max_z_score = max(z_scores)

        # å½’ä¸€åŒ–åˆ°0-1èŒƒå›´
        return min(max_z_score / 3.0, 1.0)  # 3ä¸ªæ ‡å‡†å·®ä¸ºé˜ˆå€¼

    def _detect_periodicity(
        self, timestamps: List[float], values: List[float]
    ) -> Dict[str, Any]:
        """æ£€æµ‹å‘¨æœŸæ€§"""
        if len(timestamps) < 20:
            return {}

        # ç®€å•çš„å‘¨æœŸæ€§æ£€æµ‹
        intervals = [
            timestamps[i] - timestamps[i - 1] for i in range(1, len(timestamps))
        ]
        avg_interval = statistics.mean(intervals)

        # è®¡ç®—é—´éš”çš„ä¸€è‡´æ€§
        interval_variance = statistics.variance(intervals) if len(intervals) > 1 else 0
        consistency = max(0, 1 - (interval_variance / (avg_interval**2)))

        return {
            "avg_interval": avg_interval,
            "consistency": consistency,
            "is_periodic": consistency > 0.8,
        }


class AlertHandler:
    """å‘Šè­¦å¤„ç†å™¨"""

    def __init__(self):
        self.alert_channels = []
        self.alert_history = []

    async def handle_alert(self, alert: PerformanceAlert):
        """å¤„ç†å‘Šè­¦"""
        # è®°å½•å‘Šè­¦å†å²
        self.alert_history.append(alert)

        # æ ¹æ®ä¸¥é‡ç¨‹åº¦å¤„ç†
        if alert.severity in ["high", "critical"]:
            await self._handle_critical_alert(alert)
        elif alert.severity == "medium":
            await self._handle_medium_alert(alert)
        else:
            await self._handle_low_alert(alert)

        # è®°å½•æ—¥å¿—
        logger.warning(
            f"Performance alert: {alert.message} (severity: {alert.severity})"
        )

    async def _handle_critical_alert(self, alert: PerformanceAlert):
        """å¤„ç†ä¸¥é‡å‘Šè­¦"""
        # è¿™é‡Œå¯ä»¥å®ç°ç´§æ€¥é€šçŸ¥é€»è¾‘
        # ä¾‹å¦‚ï¼šå‘é€çŸ­ä¿¡ã€é‚®ä»¶ã€Slacké€šçŸ¥ç­‰
        pass

    async def _handle_medium_alert(self, alert: PerformanceAlert):
        """å¤„ç†ä¸­ç­‰å‘Šè­¦"""
        # è¿™é‡Œå¯ä»¥å®ç°ä¸­ç­‰ä¼˜å…ˆçº§é€šçŸ¥é€»è¾‘
        pass

    async def _handle_low_alert(self, alert: PerformanceAlert):
        """å¤„ç†ä½ä¼˜å…ˆçº§å‘Šè­¦"""
        # è¿™é‡Œå¯ä»¥å®ç°ä½ä¼˜å…ˆçº§é€šçŸ¥é€»è¾‘
        pass

    def get_alert_summary(self, hours: int = 24) -> Dict[str, Any]:
        """è·å–å‘Šè­¦æ‘˜è¦"""
        cutoff_time = time.time() - (hours * 3600)
        recent_alerts = [
            alert for alert in self.alert_history if alert.timestamp >= cutoff_time
        ]

        severity_counts = defaultdict(int)
        for alert in recent_alerts:
            severity_counts[alert.severity] += 1

        return {
            "total_alerts": len(recent_alerts),
            "severity_distribution": dict(severity_counts),
            "recent_alerts": [
                {
                    "timestamp": datetime.fromtimestamp(alert.timestamp).isoformat(),
                    "metric": alert.metric_name,
                    "severity": alert.severity,
                    "message": alert.message,
                }
                for alert in recent_alerts[-10:]  # æœ€è¿‘10ä¸ªå‘Šè­¦
            ],
        }


# å…¨å±€æ€§èƒ½ç›‘æ§å®ä¾‹
performance_monitor = PerformanceMonitor()


def get_performance_monitor() -> PerformanceMonitor:
    """è·å–æ€§èƒ½ç›‘æ§å®ä¾‹"""
    return performance_monitor
