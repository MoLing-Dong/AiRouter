#!/usr/bin/env python3
"""
å®æ—¶æµå¼å“åº”æµ‹è¯•
æµ‹è¯•é›¶å»¶è¿Ÿç®¡é“æ˜¯å¦å·¥ä½œ
"""

import asyncio
import httpx
import json
import time
import os
import threading


class RealtimeStreamTest:
    def __init__(self):
        self.chunks_received = 0
        self.start_time = None
        self.first_chunk_time = None

    async def test_realtime_pipeline(self):
        """æµ‹è¯•å®æ—¶æµå¼ç®¡é“"""

        api_key = os.getenv("API_KEY")
        if not api_key:
            print("âŒ éœ€è¦è®¾ç½® API_KEY ç¯å¢ƒå˜é‡")
            return

        print("ğŸš€ å®æ—¶æµå¼ç®¡é“æµ‹è¯•")
        print("=" * 50)
        print(f"ğŸ”‘ APIå¯†é’¥: {api_key[:8]}***")
        print()

        url = "http://localhost:8000/v1/chat/completions"
        headers = {
            "Authorization": f"Bearer {api_key}",
            "Content-Type": "application/json",
            "Accept": "text/event-stream",
            "Cache-Control": "no-cache",
        }

        data = {
            "model": "gpt-3.5-turbo",
            "messages": [
                {
                    "role": "user",
                    "content": "è¯·å†™ä¸€é¦–å…³äºäººå·¥æ™ºèƒ½çš„è¯—ï¼Œè¦æ±‚æ¯ä¸ªå­—éƒ½æœ‰æ·±æ„ï¼Œå¤§çº¦200å­—",
                }
            ],
            "stream": True,
            "temperature": 0.8,
            "max_tokens": 400,
        }

        print("ğŸŒŠ å‘èµ·å®æ—¶æµå¼è¯·æ±‚...")
        print("ğŸ“¡ å»ºç«‹è¿æ¥...")

        self.start_time = time.time()

        try:
            # ä½¿ç”¨æ›´æ¿€è¿›çš„è¶…æ—¶è®¾ç½®
            timeout = httpx.Timeout(
                connect=5.0,  # è¿æ¥è¶…æ—¶
                read=1.0,  # è¯»å–è¶…æ—¶ï¼ˆæ›´çŸ­ä»¥æ£€æµ‹å»¶è¿Ÿï¼‰
                write=5.0,  # å†™å…¥è¶…æ—¶
                pool=60.0,  # è¿æ¥æ± è¶…æ—¶
            )

            async with httpx.AsyncClient(
                timeout=timeout,
                limits=httpx.Limits(max_connections=1),
                http2=False,  # å¼ºåˆ¶HTTP/1.1
            ) as client:

                async with client.stream(
                    "POST", url, json=data, headers=headers
                ) as response:

                    print(f"ğŸ“Š å“åº”çŠ¶æ€: {response.status_code}")
                    print(f"ğŸ“Š å“åº”å¤´: Connection={response.headers.get('connection')}")
                    print(f"ğŸ“Š ä¼ è¾“ç¼–ç : {response.headers.get('transfer-encoding')}")
                    print()

                    if response.status_code != 200:
                        print(f"âŒ è¯·æ±‚å¤±è´¥: {response.status_code}")
                        return

                    print("ğŸ”¥ å®æ—¶ç®¡é“å·²å»ºç«‹ï¼Œå¼€å§‹æ¥æ”¶...")
                    print("ğŸ’¬ å†…å®¹è¾“å‡º: ", end="", flush=True)

                    # ç›‘æ§çº¿ç¨‹ï¼Œæ£€æµ‹å»¶è¿Ÿ
                    stop_monitoring = False

                    def monitor_delay():
                        last_chunk_time = time.time()
                        while not stop_monitoring:
                            time.sleep(0.1)  # æ¯100msæ£€æŸ¥ä¸€æ¬¡
                            current_time = time.time()
                            if (
                                current_time - last_chunk_time > 2.0
                            ):  # è¶…è¿‡2ç§’æ²¡æœ‰æ–°chunk
                                print(
                                    f"\nâš ï¸  æ£€æµ‹åˆ°å»¶è¿Ÿ: {current_time - last_chunk_time:.1f}ç§’æ— æ–°æ•°æ®"
                                )
                                last_chunk_time = current_time

                    # å¯åŠ¨ç›‘æ§çº¿ç¨‹
                    monitor_thread = threading.Thread(target=monitor_delay, daemon=True)
                    monitor_thread.start()

                    try:
                        async for line in response.aiter_lines():
                            if line.strip():
                                current_time = time.time()
                                self.chunks_received += 1

                                # è®°å½•é¦–ä¸ªchunkæ—¶é—´
                                if self.first_chunk_time is None:
                                    self.first_chunk_time = current_time
                                    delay = self.first_chunk_time - self.start_time
                                    print(f"\nâš¡ é¦–ä¸ªchunkåˆ°è¾¾! å»¶è¿Ÿ: {delay:.3f}ç§’")
                                    print("ğŸ’¬ å†…å®¹è¾“å‡º: ", end="", flush=True)

                                # å¤„ç†SSEæ•°æ®
                                if line.startswith("data: "):
                                    data_part = line[6:]

                                    if data_part.strip() == "[DONE]":
                                        print("\nâœ… æµå¼ä¼ è¾“å®Œæˆ")
                                        break

                                    try:
                                        chunk_data = json.loads(data_part)

                                        # è·³è¿‡å¼€å§‹ä¿¡å·
                                        if chunk_data.get("type") == "stream_start":
                                            print(f"\nğŸ¬ ç®¡é“å¯åŠ¨ä¿¡å·")
                                            print("ğŸ’¬ å†…å®¹è¾“å‡º: ", end="", flush=True)
                                            continue

                                        # æå–å¹¶å®æ—¶æ˜¾ç¤ºå†…å®¹
                                        if (
                                            "choices" in chunk_data
                                            and chunk_data["choices"]
                                        ):
                                            choice = chunk_data["choices"][0]
                                            if (
                                                "delta" in choice
                                                and "content" in choice["delta"]
                                            ):
                                                content = choice["delta"]["content"]
                                                if content:
                                                    # å®æ—¶è¾“å‡ºï¼Œæ— ç¼“å†²
                                                    print(content, end="", flush=True)

                                        # æ¯50ä¸ªchunkæ˜¾ç¤ºä¸€æ¬¡ç»Ÿè®¡
                                        if self.chunks_received % 50 == 0:
                                            elapsed = current_time - self.start_time
                                            rate = self.chunks_received / elapsed
                                            print(
                                                f"\n[{elapsed:.1f}s] {self.chunks_received} chunks, {rate:.1f} chunks/s"
                                            )
                                            print("ğŸ’¬ å†…å®¹è¾“å‡º: ", end="", flush=True)

                                    except json.JSONDecodeError:
                                        pass  # å¿½ç•¥æ ¼å¼é”™è¯¯

                    finally:
                        stop_monitoring = True

                    total_time = time.time() - self.start_time

                    print(f"\n\nğŸ“Š å®æ—¶ç®¡é“æ€§èƒ½ç»Ÿè®¡:")
                    print(f"   â€¢ æ€»è€—æ—¶: {total_time:.3f}ç§’")
                    print(
                        f"   â€¢ é¦–chunkå»¶è¿Ÿ: {(self.first_chunk_time - self.start_time):.3f}ç§’"
                    )
                    print(f"   â€¢ æ€»chunkæ•°: {self.chunks_received}")
                    print(
                        f"   â€¢ å¹³å‡ä¼ è¾“ç‡: {self.chunks_received/total_time:.1f} chunks/ç§’"
                    )
                    print(
                        f"   â€¢ å¹³å‡chunké—´éš”: {total_time/self.chunks_received*1000:.1f}æ¯«ç§’"
                    )

                    # æ€§èƒ½åˆ¤æ–­
                    first_chunk_delay = self.first_chunk_time - self.start_time
                    avg_interval = total_time / self.chunks_received * 1000

                    print(f"\nğŸ¯ å®æ—¶æ€§èƒ½è¯„ä¼°:")
                    if first_chunk_delay < 1.0:
                        print("   âœ… é¦–chunkå»¶è¿Ÿä¼˜ç§€ (< 1ç§’)")
                    elif first_chunk_delay < 3.0:
                        print("   âš ï¸  é¦–chunkå»¶è¿Ÿä¸€èˆ¬ (1-3ç§’)")
                    else:
                        print("   âŒ é¦–chunkå»¶è¿Ÿè¿‡é«˜ (> 3ç§’)")

                    if avg_interval < 50:
                        print("   âœ… chunké—´éš”ä¼˜ç§€ (< 50ms)")
                    elif avg_interval < 100:
                        print("   âš ï¸  chunké—´éš”ä¸€èˆ¬ (50-100ms)")
                    else:
                        print("   âŒ chunké—´éš”è¿‡é«˜ (> 100ms)")

                    if self.chunks_received > 50:
                        print("   âœ… chunkæ•°é‡å……è¶³ï¼Œæµå¼ä½“éªŒæµç•…")
                    else:
                        print("   âš ï¸  chunkæ•°é‡è¾ƒå°‘ï¼Œå¯èƒ½å­˜åœ¨ç¼“å†²")

        except Exception as e:
            print(f"\nâŒ æµ‹è¯•å¤±è´¥: {e}")

    async def test_comparison(self):
        """å¯¹æ¯”æµ‹è¯•ï¼šæµå¼ vs éæµå¼"""
        print("\n" + "=" * 50)
        print("ğŸ”„ å¯¹æ¯”æµ‹è¯•ï¼šéæµå¼å“åº”")

        api_key = os.getenv("API_KEY")
        url = "http://localhost:8000/v1/chat/completions"
        headers = {
            "Authorization": f"Bearer {api_key}",
            "Content-Type": "application/json",
        }

        data = {
            "model": "gpt-3.5-turbo",
            "messages": [
                {
                    "role": "user",
                    "content": "è¯·å†™ä¸€é¦–å…³äºäººå·¥æ™ºèƒ½çš„è¯—ï¼Œè¦æ±‚æ¯ä¸ªå­—éƒ½æœ‰æ·±æ„ï¼Œå¤§çº¦200å­—",
                }
            ],
            "stream": False,
            "temperature": 0.8,
            "max_tokens": 400,
        }

        start_time = time.time()

        try:
            async with httpx.AsyncClient(timeout=60.0) as client:
                response = await client.post(url, json=data, headers=headers)

                total_time = time.time() - start_time

                if response.status_code == 200:
                    result = response.json()
                    content = result["choices"][0]["message"]["content"]

                    print(f"ğŸ“Š éæµå¼å“åº”:")
                    print(f"   â€¢ æ€»è€—æ—¶: {total_time:.3f}ç§’")
                    print(f"   â€¢ å†…å®¹é•¿åº¦: {len(content)}å­—ç¬¦")
                    print(f"   â€¢ ç”¨æˆ·ä½“éªŒ: ç­‰å¾…{total_time:.1f}ç§’åä¸€æ¬¡æ€§çœ‹åˆ°ç»“æœ")

                    print(f"\nğŸ’¡ å¯¹æ¯”åˆ†æ:")
                    if hasattr(self, "first_chunk_time") and self.first_chunk_time:
                        first_delay = self.first_chunk_time - self.start_time
                        print(f"   â€¢ æµå¼é¦–å­—å»¶è¿Ÿ: {first_delay:.1f}ç§’")
                        print(f"   â€¢ éæµå¼æ€»å»¶è¿Ÿ: {total_time:.1f}ç§’")
                        print(
                            f"   â€¢ æµå¼ä¼˜åŠ¿: ç”¨æˆ·æå‰{total_time - first_delay:.1f}ç§’çœ‹åˆ°å†…å®¹"
                        )
                else:
                    print(f"âŒ éæµå¼è¯·æ±‚å¤±è´¥: {response.status_code}")

        except Exception as e:
            print(f"âŒ å¯¹æ¯”æµ‹è¯•å¤±è´¥: {e}")


async def main():
    """ä¸»æµ‹è¯•å‡½æ•°"""
    tester = RealtimeStreamTest()
    await tester.test_realtime_pipeline()
    await tester.test_comparison()

    print(f"\nğŸ¯ ä¼˜åŒ–å»ºè®®:")
    print(f"   â€¢ ç¡®ä¿æœåŠ¡ä½¿ç”¨å•workeræ¨¡å¼")
    print(f"   â€¢ æ£€æŸ¥ç½‘ç»œç¯å¢ƒï¼Œé¿å…ä»£ç†ç¼“å†²")
    print(f"   â€¢ ç›‘æ§æœåŠ¡æ—¥å¿—æŸ¥çœ‹ç®¡é“çŠ¶æ€")
    print(f"   â€¢ å®æ—¶ç®¡é“çš„ç›®æ ‡æ˜¯è®©ç”¨æˆ·ç«‹å³çœ‹åˆ°å†…å®¹ç”Ÿæˆ")


if __name__ == "__main__":
    print("ğŸ”§ å®æ—¶æµå¼ç®¡é“æµ‹è¯•å·¥å…·")
    print("ä½¿ç”¨æ–¹æ³•:")
    print("  1. export API_KEY=your-volcengine-api-key")
    print("  2. python run.py  # å¯åŠ¨æœåŠ¡")
    print("  3. python realtime_test.py  # è¿è¡Œæµ‹è¯•")
    print()

    asyncio.run(main())
